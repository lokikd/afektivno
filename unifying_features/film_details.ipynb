{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# film_details\n",
    "To get the general feel for a film, we'll define some baseline characteristics. Some of these, such as conversation speed, can be compared to individual scenes; this helps us find scenes which might be particularly dramatic or emotional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../data_serialization')\n",
    "from serialization_preprocessing_io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = 'plus_one_2019'\n",
    "srt_df, subtitle_df, sentence_df, vision_df, face_df = read_pickle(film)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disregarding credits\n",
    "First, we'll need a way to disregard frames that contain the credits. This will throw off our baseline characteristics.\n",
    "\n",
    "As a quick-and-dirty way of accomplishing this, we can look for the last frame that has a face in it, and then disregard every frame after that. This is available as `generate_nocreds_dfs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_before_credits = face_df[face_df['faces_found'] > 0].tail(1).index[0]  # final frame before credits\n",
    "vision_nocreds_df = vision_df[0:frame_before_credits].copy()\n",
    "face_nocreds_df = face_df[0:frame_before_credits].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion\n",
    "### Upset Percentage\n",
    "We can try and get a feel for overall emotion of the film by looking at the emotion in dialogue scenes. We can count the number of \"sad\" and \"angry\" faces are found, as a percentage of overall facial emotions. This is available as `get_upset_percentage()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45010845986984815"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    sad_percentage = face_nocreds_df.p_emotion.value_counts(normalize=True)['sad']\n",
    "except KeyError:\n",
    "    sad_percentage = 0\n",
    "try:\n",
    "    angry_percentage = face_nocreds_df.p_emotion.value_counts(normalize=True)['angry']\n",
    "except KeyError:\n",
    "    angry_percentage = 0\n",
    "\n",
    "upset_emotion_percentage = sad_percentage + angry_percentage\n",
    "upset_emotion_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogue Vibe\n",
    "### Profanity Per Word\n",
    "First, we'll take a look at the dialogue. We'll first quantify how much profanity is in the film as a whole. We'll look for \"profanity per word\", like \"1 in X words is a profanity\". After we calculate this, we'll be able to search for dramatic scenes with an above-average amount of profanity.\n",
    "\n",
    "First, we'll count all the words in spoken sentences. Then we'll count up the number of profanities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_count = 0\n",
    "sentence_list = sentence_df.sentence.tolist()\n",
    "for sentence in sentence_list:\n",
    "    for character in sentence:\n",
    "        if character.isspace():\n",
    "            space_count += 1\n",
    "word_count = space_count + len(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008517324071777061"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profanity_count = sentence_df.profanity.sum()\n",
    "profanity_per_word = profanity_count/word_count\n",
    "profanity_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One in 117 words is a profanity.\n"
     ]
    }
   ],
   "source": [
    "if profanity_per_word == 0:\n",
    "    print('The film contains no profanity.')\n",
    "else:\n",
    "    print('One in', round(1 / profanity_per_word), 'words is a profanity.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is available as a function `get_profanity_per_word()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cadence\n",
    "The speed of conversation is an important metric. Witty comedies might have characters launch lightning-fast insults at each other. Introspective dramas or quiet romances might have very little dialogue. We can measure cadence by counting the sentences per minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(len(sentence_df) / (len(vision_df) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words per Sentence\n",
    "Dramas may have lengthy, wordy monologues. Comedies may contain rapid-fire arguments. We can take a look at words per sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0043046357615895"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_count = 0\n",
    "sentence_list = sentence_df.sentence.tolist()\n",
    "for sentence in sentence_list:\n",
    "    for character in sentence:\n",
    "        if character.isspace():\n",
    "            space_count += 1\n",
    "\n",
    "word_count = space_count + len(sentence_list)\n",
    "\n",
    "words_per_sentence = word_count / len(sentence_list)\n",
    "words_per_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Style\n",
    "There are a few technical computer vision details that may be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect Ratio: 2.39\n",
      "Average shot duration: 3.73\n",
      "Average frame brightness: 59\n",
      "Average frame contrast: 44\n"
     ]
    }
   ],
   "source": [
    "print('Aspect Ratio:', vision_nocreds_df.aspect_ratio.value_counts().index[0])\n",
    "print('Average shot duration:', round(len(vision_nocreds_df) / vision_nocreds_df.shot_id.max(), 2))\n",
    "print('Average frame brightness:', round(vision_nocreds_df.brightness.mean()))\n",
    "print('Average frame contrast:', round(vision_nocreds_df.contrast.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these statistics are bundled together in the function `display_film_baseline()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
