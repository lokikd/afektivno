{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scene_details\n",
    "Since we can automatically identify a few scenes of a film, we can begin taking a closer look at each. In this notebook, we'll try and identify as many features as we can: the level of drama in the dialogue, the emotions of the characters, the mood of the score, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from time_reference_io import *\n",
    "from film_details_io import *\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from scene_identification_io import *\n",
    "sys.path.append('../subtitle_features')\n",
    "from subtitle_dataframes_io import *\n",
    "sys.path.append('../audio_features')\n",
    "from audio_processing_io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = 'lost_in_translation_2003'\n",
    "srt_df, subtitle_df, sentence_df, vision_df, face_df = read_pickle(film)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Scene-Specific DataFrames\n",
    "We have a function to create a dictionary of scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_dictionaries = generate_scenes(vision_df, face_df, substantial_minimum=4, anchor_search=6)\n",
    "len(scene_dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scene_id': 3,\n",
       " 'first_frame': 2489,\n",
       " 'last_frame': 2533,\n",
       " 'scene_duration': 45,\n",
       " 'left_anchor_shot_cluster': 196,\n",
       " 'left_anchor_face_cluster': 18.0,\n",
       " 'matching_left_face_clusters': [9.0, 12.0],\n",
       " 'right_anchor_shot_cluster': 38,\n",
       " 'right_anchor_face_cluster': 6.0,\n",
       " 'matching_right_face_clusters': [],\n",
       " 'cutaway_shot_clusters': [29]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_dict = scene_dictionaries[3]\n",
    "scene_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dictionary gives us the first and last frames. We can use these to create new vision- and subtitle-related dataframes containing only data from this scene.\n",
    "### Vision DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_vision_df = vision_df[scene_dict['first_frame'] - 1:scene_dict['last_frame']]\n",
    "scene_face_df = face_df[scene_dict['first_frame'] - 1:scene_dict['last_frame']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtitle DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_duration = scene_dict['last_frame'] + 1 - scene_dict['first_frame']\n",
    "scene_start_time = frame_to_time(scene_dict['first_frame'])\n",
    "scene_end_time = frame_to_time(scene_dict['last_frame'] + 1) # add 1 second; scene ends one second after this frame is onscreen\n",
    "scene_subtitle_df = subtitle_df[\n",
    "    (subtitle_df['end_time'] > scene_start_time) & (subtitle_df['start_time'] < scene_end_time)].copy()\n",
    "\n",
    "scene_sentence_indices = []\n",
    "x = 0\n",
    "for sub_index_list in sentence_df.subtitle_indices.values:\n",
    "    for sub_index in sub_index_list:\n",
    "        if sub_index in scene_subtitle_df.index.values:\n",
    "            scene_sentence_indices.append(x)\n",
    "    x += 1\n",
    "scene_sentence_df = sentence_df[scene_sentence_indices[0]: scene_sentence_indices[-1] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srt_index</th>\n",
       "      <th>original_text</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>concat_sep_text</th>\n",
       "      <th>separated_flag</th>\n",
       "      <th>laugh</th>\n",
       "      <th>hesitation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>music</th>\n",
       "      <th>parenthetical</th>\n",
       "      <th>el_parenthetical</th>\n",
       "      <th>el_italic</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>631</td>\n",
       "      <td>(GIGGLES)\\nHello.</td>\n",
       "      <td>00:41:30.488000</td>\n",
       "      <td>00:41:31.780000</td>\n",
       "      <td>(GIGGLES) Hello.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>GIGGLES</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>632</td>\n",
       "      <td>Hello.\\nHow are you?</td>\n",
       "      <td>00:41:31.865000</td>\n",
       "      <td>00:41:33.073000</td>\n",
       "      <td>Hello. How are you?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello. How are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>633</td>\n",
       "      <td>Good. How are you?</td>\n",
       "      <td>00:41:33.158000</td>\n",
       "      <td>00:41:34.575000</td>\n",
       "      <td>Good. How are you?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Good. How are you?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     srt_index         original_text       start_time         end_time  \\\n",
       "630        631     (GIGGLES)\\nHello.  00:41:30.488000  00:41:31.780000   \n",
       "631        632  Hello.\\nHow are you?  00:41:31.865000  00:41:33.073000   \n",
       "632        633    Good. How are you?  00:41:33.158000  00:41:34.575000   \n",
       "\n",
       "         concat_sep_text  separated_flag  laugh  hesitation speaker  music  \\\n",
       "630     (GIGGLES) Hello.               0      1           0    None      0   \n",
       "631  Hello. How are you?               0      0           0    None      0   \n",
       "632   Good. How are you?               0      0           0    None      0   \n",
       "\n",
       "    parenthetical  el_parenthetical  el_italic         cleaned_text  \n",
       "630       GIGGLES                 0          0               Hello.  \n",
       "631          None                 0          0  Hello. How are you?  \n",
       "632          None                 0          0   Good. How are you?  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_subtitle_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>subtitle_indices</th>\n",
       "      <th>profanity</th>\n",
       "      <th>self_intro</th>\n",
       "      <th>other_intro</th>\n",
       "      <th>direct_address</th>\n",
       "      <th>conv_boundary</th>\n",
       "      <th>offscreen_speaker</th>\n",
       "      <th>implied_speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>Hello.</td>\n",
       "      <td>[630]</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Hello.</td>\n",
       "      <td>[631]</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>How are you?</td>\n",
       "      <td>[631]</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>starter</td>\n",
       "      <td>None</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence subtitle_indices  profanity self_intro other_intro  \\\n",
       "721        Hello.            [630]          0       None        None   \n",
       "722        Hello.            [631]          0       None        None   \n",
       "723  How are you?            [631]          0       None        None   \n",
       "\n",
       "    direct_address conv_boundary offscreen_speaker  implied_speaker  \n",
       "721           None          None              None              NaN  \n",
       "722           None          None              None             18.0  \n",
       "723           None       starter              None             18.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_sentence_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of vision and subtitle DataFrames are available as a function `generate_scene_level_dfs()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio File\n",
    "We don't yet have DataFrames for audio, but we can extract the scene-specific audio from the film's overall audio track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted audio file: ../extracted_audio/lost_in_translation_2003/2489_2533.wav\n"
     ]
    }
   ],
   "source": [
    "extract_scene_audio(film, scene_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Vibe\n",
    "While we can't completely read and understand the dialogue of a film just yet, we can attempt to quantify the general \"vibe\" of a scene's conversation.\n",
    "### Cadence\n",
    "The speed of conversation is an important metric. Witty comedies might have characters launch lightning-fast insults at each other. Introspective dramas or quiet romances might have very little dialogue. We can measure cadence by counting the sentences per minute of a scene. This is available as a function `get_scene_cadence()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.333333333333332"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_duration = len(scene_vision_df)\n",
    "cadence = len(scene_subtitle_df) / (scene_duration / 60)\n",
    "cadence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This scene has a medium cadence, with a conversation speed of 21 sentences per minute.\n"
     ]
    }
   ],
   "source": [
    "if round(cadence) >= 35:\n",
    "    print('This scene has a fast cadence, with a conversation speed of', round(cadence), 'sentences per minute.')\n",
    "elif round(cadence) < 20:\n",
    "    print('This scene has a slow cadence, with a conversation speed of', round(cadence), 'sentences per minute.')\n",
    "else:\n",
    "    print('This scene has a medium cadence, with a conversation speed of', round(cadence), 'sentences per minute.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profanity\n",
    "Profanity can indicate drama. A heated argument between characters might have much more profanity than the rest of the film. We'll measure this as profanity per word, as the function `get_scene_ppw()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_count = 0\n",
    "sentence_list = scene_sentence_df.sentence.tolist()\n",
    "for sentence in sentence_list:\n",
    "    for character in sentence:\n",
    "        if character.isspace():\n",
    "            space_count += 1\n",
    "\n",
    "word_count = space_count + len(sentence_list)\n",
    "profanity_count = scene_sentence_df.profanity.sum()\n",
    "\n",
    "profanity_per_word = profanity_count/word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scene contains no profanity.\n"
     ]
    }
   ],
   "source": [
    "if profanity_per_word == 0:\n",
    "    print('The scene contains no profanity.')\n",
    "else:\n",
    "    print('One in', round(1 / profanity_per_word), 'words is a profanity.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Vibe (print only)\n",
    "We have a few other ways of getting the feel for a conversation, but they aren't worth making into functions which return a value, either because of their ease of calculation, or their experimental nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laughter/Hesitations\n",
    "Laughter and hesitations were already calculated during data serialization, so we just have to count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 instances of laughter.\n",
      "There are 0 midsentence hesitation interjections.\n"
     ]
    }
   ],
   "source": [
    "print('There are', scene_subtitle_df.laugh.sum(), 'instances of laughter.')\n",
    "print('There are', scene_subtitle_df.hesitation.sum(), 'midsentence hesitation interjections.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Icebreaker and Kicker\n",
    "The beginning and end of a scene might help dictate the scene's plot impact. (Why was this scene important?)\n",
    "\n",
    "`display_scene_start_end()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Icebreaker (Conversation Start)\n",
      "-------------------------------\n",
      "Hello.\n",
      "Hello.\n",
      "How are you?\n",
      "\n",
      "\n",
      "-------------------------\n",
      "Kicker (Conversation End)\n",
      "-------------------------\n",
      "I'll see you later.\n",
      "Okay.\n",
      "See you.\n"
     ]
    }
   ],
   "source": [
    "scene_sentences = scene_sentence_df.sentence.tolist()\n",
    "print('-------------------------------')\n",
    "print('Icebreaker (Conversation Start)')            # first three sentences of scene\n",
    "print('-------------------------------')\n",
    "print(scene_sentences[0])\n",
    "print(scene_sentences[1])\n",
    "print(scene_sentences[2])\n",
    "print()\n",
    "print()\n",
    "print('-------------------------')\n",
    "print('Kicker (Conversation End)')                  # final three sentences of scene\n",
    "print('-------------------------')\n",
    "print(scene_sentences[-3])\n",
    "print(scene_sentences[-2])\n",
    "print(scene_sentences[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directed Questions, Declarations, and Direct Addresses\n",
    "With NLP, we can look at specific patterns in words' parts of speech, to try and find the following:\n",
    "- Directed Questions: Questions that address \"you\" (and their possible responses)\n",
    "- First-Person Declarations: Sentences with \"I\" as a subject\n",
    "- Second-Person Direct Addresses: Sentences directly addressing \"you\"\n",
    "\n",
    "`display_scene_important_sentences()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "scene_sentence_doc = nlp((' '.join(scene_sentence_df.sentence.tolist())))\n",
    "sent_nlp_list = list(scene_sentence_doc.sents)\n",
    "\n",
    "direct_question_indices = []\n",
    "x = 0\n",
    "for sent in sent_nlp_list:\n",
    "    if sent[-1].text == '?':\n",
    "        for token in sent:\n",
    "            if token.dep_ == 'nsubj' and token.text == 'you':\n",
    "                direct_question_indices.append(x)\n",
    "    x += 1\n",
    "direct_question_indices = list(set(direct_question_indices))\n",
    "\n",
    "\n",
    "i_indices = []\n",
    "x = 0\n",
    "for sent in sent_nlp_list:\n",
    "    for token in sent:\n",
    "        if token.dep_ == 'nsubj' and token.text == 'I' and sent[-1].text != '?':\n",
    "            if x not in i_indices:\n",
    "                i_indices.append(x)\n",
    "    x += 1\n",
    "\n",
    "\n",
    "you_indices = []\n",
    "x = 0\n",
    "for sent in sent_nlp_list:\n",
    "    if sent[-1].text != '?':\n",
    "        for token in sent:\n",
    "            if token.dep_ == 'nsubj' and token.text == 'you':\n",
    "                if x not in you_indices:\n",
    "                    you_indices.append(x)\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Directed Questions and Responses\n",
      "--------------------------------\n",
      "How are you?\n",
      "Good.\n",
      "\n",
      "How are you?\n",
      "It's a cool pool, isn't it?\n",
      "\n",
      "How long you staying for?\n",
      "I'll be in the bar for the rest of the week.\n",
      "\n",
      "-------------------------\n",
      "First-Person Declarations\n",
      "-------------------------\n",
      "I'll be in the bar for the rest of the week.\n",
      "I'm going out with some friends later, if you wanna come...\n",
      "I'll see you later.\n",
      "\n",
      "-----------------------\n",
      "Second-Person Addresses\n",
      "-----------------------\n",
      "I'm going out with some friends later, if you wanna come...\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------')\n",
    "print('Directed Questions and Responses')       # second-person questions directed at \"you\"\n",
    "print('--------------------------------')\n",
    "for index in direct_question_indices:\n",
    "    print(sent_nlp_list[index])\n",
    "    print(sent_nlp_list[index + 1])\n",
    "    print()\n",
    "print('-------------------------')\n",
    "print('First-Person Declarations')\n",
    "print('-------------------------')\n",
    "for index in i_indices:\n",
    "    print(sent_nlp_list[index])\n",
    "print()\n",
    "print('-----------------------')\n",
    "print('Second-Person Addresses')\n",
    "print('-----------------------')\n",
    "for index in you_indices:\n",
    "    print(sent_nlp_list[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF and Noun Groups\n",
    "We can try various methods of finding important phrases or nouns.\n",
    "\n",
    "`display_scene_important_phrases()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Possible Important Terms, TF-IDF\n",
      "--------------------------------\n",
      "['later', 'good', 'll', 'okay', 'hello']\n",
      "\n",
      "-------------------------------------\n",
      "Possible Important Terms, Noun Groups\n",
      "-------------------------------------\n",
      "['a cool pool', 'any sleep', 'the bar', 'the rest', 'the week']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tf_idf data preparation\n",
    "film_doc = sentence_df.sentence.tolist()\n",
    "scene_doc = scene_sentence_df.sentence.tolist()\n",
    "del film_doc[scene_sentence_indices[0]: scene_sentence_indices[-1] + 1]\n",
    "scene_doc_joined = (' '.join(scene_doc))\n",
    "film_doc_joined = (' '.join(film_doc))\n",
    "film_scene_doc = [scene_doc_joined, film_doc_joined]\n",
    "\n",
    "# tf-idf\n",
    "vectorizer = TfidfVectorizer(use_idf=True, stop_words='english', ngram_range=(1, 3))\n",
    "idf_transformed = vectorizer.fit_transform(film_scene_doc)\n",
    "tf_idf_df = pd.DataFrame(idf_transformed[0].T.todense(), index=vectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "tf_idf_df = tf_idf_df.sort_values('TF-IDF', ascending=False)\n",
    "tf_idf_terms = list(tf_idf_df.head(5).index)\n",
    "\n",
    "\n",
    "\n",
    "noun_groups = []\n",
    "for group in scene_sentence_doc.noun_chunks:\n",
    "    if group.root.pos_ != 'PRON':\n",
    "        noun_groups.append(str(group))\n",
    "ng_count = Counter(noun_groups)\n",
    "ng_terms = []\n",
    "for ng in ng_count.most_common(5):\n",
    "    ng_terms.append(ng[0])\n",
    "\n",
    "print('--------------------------------')\n",
    "print('Possible Important Terms, TF-IDF')\n",
    "print('--------------------------------')\n",
    "print(tf_idf_terms)\n",
    "print()\n",
    "print('-------------------------------------')\n",
    "print('Possible Important Terms, Noun Groups')\n",
    "print('-------------------------------------')\n",
    "print(ng_terms)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene Emotions\n",
    "By checking each characters' emotion on each frames, we can calculate their primary emotion of the scene.\n",
    "\n",
    "`display_scene_emotions()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left character, with face clusters [18.0, 9.0, 12.0] has the primary emotion: sad, in 57% of frames\n",
      "Right character, with face clusters [6.0] has the primary emotion: happy, in 38% of frames\n"
     ]
    }
   ],
   "source": [
    "left_face_clusters = [scene_dict['left_anchor_face_cluster']]\n",
    "for matching_cluster in scene_dict['matching_left_face_clusters']:\n",
    "    left_face_clusters.append(matching_cluster)\n",
    "right_face_clusters = [scene_dict['right_anchor_face_cluster']]\n",
    "for matching_cluster in scene_dict['matching_right_face_clusters']:\n",
    "    right_face_clusters.append(matching_cluster)\n",
    "left_emotion_index = scene_face_df[scene_face_df.p_face_cluster.isin(left_face_clusters)].p_emotion.value_counts(normalize=True).index[0]\n",
    "left_emotion_percentage = scene_face_df[scene_face_df.p_face_cluster.isin(left_face_clusters)].p_emotion.value_counts(normalize=True).values[0]\n",
    "print('Left character, with face clusters', left_face_clusters, 'has the primary emotion:', left_emotion_index + ', in ' + '{:.0%}'.format(left_emotion_percentage) + ' of frames')\n",
    "right_emotion_index = scene_face_df[scene_face_df.p_face_cluster.isin(right_face_clusters)].p_emotion.value_counts(normalize=True).index[0]\n",
    "right_emotion_percentage = scene_face_df[scene_face_df.p_face_cluster.isin(right_face_clusters)].p_emotion.value_counts(normalize=True).values[0]\n",
    "print('Right character, with face clusters', right_face_clusters, 'has the primary emotion:', right_emotion_index +\n",
    "      ', in ' + '{:.0%}'.format(right_emotion_percentage) + ' of frames')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
