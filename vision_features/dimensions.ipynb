{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimensions\n",
    "We'll be using `OpenCV` to analyze individual movie frames. We can extract a few features from the frames' image size. We can also designate several \"points of interest\" in the frame, which would be useful, for example, in detecting if a character's face is positioned in the frame according to the rule-of-thirds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Image Data\n",
    "The below code blocks contain the basic process of loading an image file as an image object. We'll turn this into a single-line function in `vision_features_io`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from vision_features_io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "film = 'teen_spirit'\n",
    "frame = 1335\n",
    "frame_folder = os.path.join('../frame_per_second', film)\n",
    "img_path = frame_folder + '/' + film + '_frame' + str(frame) + '.jpg'\n",
    "image = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Dimensions\n",
    "After loading the image, we have an array of arrays containing BGR color values of individual pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = load_frame('teen_spirit', 1335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 854, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrowing\n",
    "We may also want to unrow the frame data, with just a single array containing BGR color values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304024, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrowed_list = []\n",
    "for y in frame:\n",
    "    for pixel in y:\n",
    "        unrowed_list.append(pixel)\n",
    "\n",
    "unrowed = np.array(unrowed_list)\n",
    "\n",
    "unrowed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height and Width\n",
    "We can get the height and width. From there, we can calculate the aspect ratio. In this case, it's 2.4, a very common cinema widescreen ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height = frame.shape[0]\n",
    "height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = frame.shape[1]\n",
    "width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_ratio = round(width/height, 2)\n",
    "aspect_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Aspect Ratio\n",
    "Films sometimes switch aspect ratios for various reasons. Two common purposes:\n",
    "1. The characters are watching a film-within-a-film. The aspect ratio will switch to something more cinematic by blocking off the top and bottom of the image with black bars.\n",
    "2. The audience is watching footage from the past. This is apparent in the opening credits of *Succession*, where \"vintage\", sepia-toned footage of the main characters as children is interspersed with modern-day footage. The modern-day footage is in the show's natural aspect ratio, while vintage footage is in a narrower aspect ratio, with black bars on the left and right.\n",
    "To detect an artificial aspect ratio, we can search for black bars in either scenario: top/bottom, or left/right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black Bars on Top and Bottom - Cinematic Black Rows\n",
    "We'll first detect cinematic black bars on the top and bottom of the frame. In this example from *Rides Start at 10:00*, black rows are used in a film-within-a-film context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = load_frame('rides', 700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a function that will help detect rows with all-black pixels. Because of video compression, some video files may not achieve \"true\" black in these situations, and we'll set a tolerance of 5 (on the RGB 0-255) scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_row(image, row_selection):\n",
    "    \n",
    "    total_pixels = image.shape[1]\n",
    "    black_pixels = 0\n",
    "\n",
    "    for pixel in image[row_selection]:\n",
    "        if pixel.mean() < 5:\n",
    "            black_pixels += 1\n",
    "    \n",
    "    if black_pixels == total_pixels:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_row(frame, 3) #all-black pixels detected on the fourth-from-top row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can iteratively search from the top/bottom edges, and approach the center until we don't find any more all-black rows. We're left with the highest and lowest rows that are part of the black bars. We can define the \"true height\" by subtracting the two - the true height is comprised of the remaining rows once we remove the black bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_height(image):\n",
    "    top_row = 0\n",
    "    bottom_row = image.shape[0] - 1\n",
    "    search_flag = True\n",
    "    first_flag = True\n",
    "\n",
    "    while search_flag == True:\n",
    "        if black_row(image, top_row) and black_row(image, bottom_row):\n",
    "            top_row += 1\n",
    "            bottom_row -= 1\n",
    "            first_flag = False\n",
    "        elif first_flag == True:\n",
    "            return image.shape[0]   # if the first search doesn't yield black columns, simply return frame height\n",
    "        else:\n",
    "            search_flag = False\n",
    "\n",
    "        bottom_row += 1      # necessary because we had to subtract 1 when declaring bottom_row\n",
    "            \n",
    "    return bottom_row - top_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n",
      "418\n"
     ]
    }
   ],
   "source": [
    "print(frame.shape[0])\n",
    "print(true_height(frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black Bars on Left and Right - Vintage Black Columns\n",
    "Next, we'll look detect black bars on the left and right of the frame. In this example from *Vault*, black columns are used in a vintage context to show footage from the '70s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = load_frame('vault', 205)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we first define a function to seek a single entity of the black bar: an all-black column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_column(image, col_selection):\n",
    "    \n",
    "    total_pixels = image.shape[0]\n",
    "    black_pixels = 0\n",
    "\n",
    "    for row in image:\n",
    "        if row[col_selection].mean() < 5:\n",
    "            black_pixels += 1\n",
    "    \n",
    "    if black_pixels == total_pixels:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function, we start from the left- and right-most edge columns, and work our way inwards until we get to columns with actual content. The \"true width\" is much smaller than the actual frame file's width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_width(image):\n",
    "    left_column = 0\n",
    "    right_column = image.shape[1] - 1    # list starts at 0, while .shape starts at 1\n",
    "    search_flag = True\n",
    "    first_flag = True\n",
    "\n",
    "    while search_flag == True:\n",
    "        if black_column(image, left_column) and black_column(image, right_column):\n",
    "            left_column += 1\n",
    "            right_column -= 1\n",
    "            first_flag = False\n",
    "        elif first_flag == True:     # if the first search doesn't yield black columns, simply return frame width\n",
    "            return image.shape[1]\n",
    "        else:\n",
    "            search_flag = False\n",
    "\n",
    "        right_column += 1      # necessary because we had to subtract 1 when declaring right_column\n",
    "            \n",
    "    return right_column - left_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854\n",
      "694\n"
     ]
    }
   ],
   "source": [
    "print(frame.shape[1])\n",
    "print(true_width(frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Aspect Ratio\n",
    "We can use these \"true\" widths and heights to find the actual aspect ratio, and compare it to the original aspect ratio (of the frame image size). If there's a difference, this part of the frame may have special qualities (vintage, film-within-a-film, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame height: 362\n",
      "True image height: 362\n",
      "Frame width: 854\n",
      "True image width: 694\n"
     ]
    }
   ],
   "source": [
    "print('Frame height:', frame.shape[0])\n",
    "print('True image height:', true_height(frame))\n",
    "print('Frame width:', frame.shape[1])\n",
    "print('True image width:', true_width(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame aspect ratio: 2.36\n",
      "True aspect ratio: 1.92\n"
     ]
    }
   ],
   "source": [
    "print('Frame aspect ratio:', round(frame.shape[1]/frame.shape[0], 2))\n",
    "print('True aspect ratio:', round(true_width(frame)/true_height(frame), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Points of Interest\n",
    "We can designate specific points in the frame as points of interest. \n",
    "### Center\n",
    "Certain directors, most notably Wes Anderson, like to compose characters, objects, or other physical elements in the center of the frame. In addition, some \"split-screen\" scenes can be identified by a central border and left- and right-half images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_height = round(height * (1/2))\n",
    "half_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_width = round(width * (1/2))\n",
    "half_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 427)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_point = (half_height, half_width)\n",
    "center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(center_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule of Thirds\n",
    "The rule of thirds is an important axiom of cinemtography and photography. Rather than placing characters, objects, or horizon lines in the dead-center of frame (one-half), they can be placed at one- or two-thirds of the total width or height. Horizon lines are often placed at one-third of frame height, allowing two-thirds of the frame to be occupied by sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 height: 119\n",
      "2/3 height: 237\n",
      "1/3 width: 285\n",
      "2/3 width: 569\n"
     ]
    }
   ],
   "source": [
    "one_third_height = round(height * (1/3))\n",
    "two_thirds_height = round(height * (2/3))\n",
    "one_third_width = round(width * (1/3))\n",
    "two_thirds_width = round(width * (2/3))\n",
    "print('1/3 height:', one_third_height)\n",
    "print('2/3 height:', two_thirds_height)\n",
    "print('1/3 width:', one_third_width)\n",
    "print('2/3 width:', two_thirds_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cinematographers will often position characters or other prominent objects at the intersection of (1/3) or (2/3) width and height. There are four points where the rule of thirds applies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule of Thirds Point A: (119, 285)\n",
      "Rule of Thirds Point B: (237, 285)\n",
      "Rule of Thirds Point C: (119, 569)\n",
      "Rule of Thirds Point D: (237, 569)\n"
     ]
    }
   ],
   "source": [
    "thirds_point_a = (one_third_height, one_third_width)\n",
    "thirds_point_b = (two_thirds_height, one_third_width)\n",
    "thirds_point_c = (one_third_height, two_thirds_width)\n",
    "thirds_point_d = (two_thirds_height, two_thirds_width)\n",
    "print('Rule of Thirds Point A:', thirds_point_a)\n",
    "print('Rule of Thirds Point B:', thirds_point_b)\n",
    "print('Rule of Thirds Point C:', thirds_point_c)\n",
    "print('Rule of Thirds Point D:', thirds_point_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
