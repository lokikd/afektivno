{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# key_dialogue\n",
    "With each sentence of the film captured in a dataframe, we can try and pick out the most important, or information-dense dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subtitle_dataframes_io import *\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pysrt.open('../subtitles/plus_one_2019.srt')\n",
    "subtitle_df = generate_base_subtitle_df(subs)\n",
    "subtitle_df = generate_subtitle_features(subtitle_df)\n",
    "subtitle_df['cleaned_text'] = subtitle_df['concat_sep_text'].map(clean_line)\n",
    "sentences = partition_sentences(remove_blanks(subtitle_df['cleaned_text'].tolist()), nlp)\n",
    "subtitle_indices = tie_sentence_subtitle_indices(sentences, subtitle_df)\n",
    "sentence_df = pd.DataFrame(list(zip(sentences, subtitle_indices)), columns=['sentence', 'subtitle_indices'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-Person Declarations\n",
    "We can look for first-person declarations, sentences where the subject of the sentence is \"I\". When a character speaks in this manner, she may be declaring something of personal note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_sentence_df = sentence_df[2788:2821].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_sentence_doc = nlp((' '.join(scene_sentence_df.sentence.tolist())))\n",
    "sent_nlp_list = list(scene_sentence_doc.sents)\n",
    "\n",
    "i_indices = []\n",
    "x = 0\n",
    "for sent in sent_nlp_list:\n",
    "    for token in sent:\n",
    "        if token.dep_ == 'nsubj' and token.text == 'I' and sent[-1].text != '?':\n",
    "            if x not in i_indices:\n",
    "                i_indices.append(x)\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just need to say one thing, and I'll...\n",
      "I'll leave you alone, I swear.\n",
      "I really can't handle a big speech right now, Ben.\n",
      "I'm an asshole.\n",
      "I-I can't do them on my own.\n",
      "You're not there to... to insult everything that I do.\n",
      "And the worst part about all this is that you're not there because I hurt you.\n",
      "I hurt the one person that never deserved it.\n",
      "And I pushed you away because I'm dumb\n",
      "and I'm selfish, and fuck me for being too late,\n",
      "but I love you, Alice.\n",
      "Um, I should really go back inside.\n"
     ]
    }
   ],
   "source": [
    "for index in i_indices:\n",
    "    print(sent_nlp_list[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second-Person Addresses\n",
    "We can also look for second-person addresses, one person speaking to another character, where \"you\" is being addressed directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "you_indices = []\n",
    "x = 0\n",
    "for sent in sent_nlp_list:\n",
    "    if sent[-1].text != '?':\n",
    "        for token in sent:\n",
    "            if token.dep_ == 'nsubj' and token.text == 'you':\n",
    "                if x not in you_indices:\n",
    "                    you_indices.append(x)\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice, you were right.\n",
      "And you were right about these weddings.\n",
      "It's 'cause you're lonely.\n",
      "It's because you're not there.\n",
      "And the worst part about all this is that you're not there because I hurt you.\n"
     ]
    }
   ],
   "source": [
    "for index in you_indices:\n",
    "    print(sent_nlp_list[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed Questions\n",
    "A crucial component of movie dialogue is the \"directed question\", a question that a character asks another, in second-person. This is a slight varation on the \"second-person address\" above, but looks for the question mark.\n",
    "\n",
    "We can also attempt to record the response to these questions. For now, we'll look for the sentence directly after a directed question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pysrt.open('../subtitles/lost_in_translation_2003.srt')\n",
    "subtitle_df = generate_base_subtitle_df(subs)\n",
    "subtitle_df = generate_subtitle_features(subtitle_df)\n",
    "subtitle_df['cleaned_text'] = subtitle_df['concat_sep_text'].map(clean_line)\n",
    "sentences = partition_sentences(remove_blanks(subtitle_df['cleaned_text'].tolist()), nlp)\n",
    "subtitle_indices = tie_sentence_subtitle_indices(sentences, subtitle_df)\n",
    "sentence_df = pd.DataFrame(list(zip(sentences, subtitle_indices)), columns=['sentence', 'subtitle_indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_sentence_df = sentence_df[721:741].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_sentence_doc = nlp((' '.join(scene_sentence_df.sentence.tolist())))\n",
    "sent_nlp_list = list(scene_sentence_doc.sents)\n",
    "\n",
    "direct_question_indices = []\n",
    "x = 0\n",
    "for sent in sent_nlp_list:\n",
    "    if sent[-1].text == '?':\n",
    "        for token in sent:\n",
    "            if token.dep_ == 'nsubj' and token.text == 'you':\n",
    "                direct_question_indices.append(x)\n",
    "    x += 1\n",
    "direct_question_indices = list(set(direct_question_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you?\n",
      "Good.\n",
      "\n",
      "How are you?\n",
      "It's a cool pool, isn't it?\n",
      "\n",
      "How long you staying for?\n",
      "I'll be in the bar for the rest of the week.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in direct_question_indices:\n",
    "    print(sent_nlp_list[index])\n",
    "    print(sent_nlp_list[index + 1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scene, we picked up three directed questions and their responses. (\"How are you?\" was asked twice, so there's two separate responses.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
