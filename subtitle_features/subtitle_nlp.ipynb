{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subtitle_nlp\n",
    "With the subtitles' lines of dialogue cleaned, we can begin our language analyses using the `spaCy` NLP library. We've previously defined a few functions to load the subtitles file, clean the subtitle text, and populate them into a single list. We'll look at the subtitle file for *Booksmart* (2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysrt\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from subtitle_cleaning_io import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pysrt.open('../subtitles/booksmart.srt')\n",
    "subs.insert(0, subs[0])\n",
    "cleaned_lines = clean_subs(subs)\n",
    "input_lines = remove_blanks(cleaned_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2270"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a cleaned list of subtitle lines, we can load it into `spaCy`. First we define a spacy English model object, and then pass in a single long string of the subtitle text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "doc = nlp(' '.join(input_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "`spaCy` allows for easy NER, or identification of proper nouns. They'll be grouped into categories like \"PERSON\" or \"ORG\". We'll look at these two.\n",
    "### Characters\n",
    "The audience learns who the names of characters by listening to the dialogue (except for the cases where character names are displayed onscreen, most often in documentaries or docu-dramatizations). By counting the most common \"PERSON\" entites, we may be able to get an idea of who the characters are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PERSON':\n",
    "        people.append(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Amy', 49),\n",
       " ('Molly', 20),\n",
       " ('Nick', 17),\n",
       " ('Ryan', 13),\n",
       " ('Dude', 9),\n",
       " ('Gigi', 9),\n",
       " ('Fine', 8),\n",
       " ('Mm-hmm', 8),\n",
       " ('Malala', 8),\n",
       " ('Jesus Christ', 7),\n",
       " ('Whoo', 6),\n",
       " ('Alan', 6),\n",
       " ('Jesus', 6),\n",
       " ('Principal Brown', 5),\n",
       " ('Gege', 5)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This worked out pretty well, Amy and Molly are the main characters, and many of the secondary names appear in this list. Epithets and slang like \"Dude\" and \"Jesus Christ\" can be hard-coded in an exception list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organization\n",
    "This entity category has a wider reach than its name implies. It will not only catch organizations, companies, and institutions, but also do its best to identify made-up groups or organizations through context. Below, it has identified two colleges, as well as \"Nick's\". The entire film revolves around Amy and Molly trying to get to a party at Nick's house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Nick's\", 19), ('Yale', 7), ('Nick', 3), ('WOMAN', 2), ('Columbia', 2)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'ORG':\n",
    "        entities.append(ent.text)\n",
    "count = Counter(entities)\n",
    "count.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Boundary Detection\n",
    "A short sentence may only need one subtitle, but longer sentences may span two or more (in series, one at a time).\n",
    "\n",
    "`516\n",
    "00:18:17,722 --> 00:18:20,683\n",
    "I'm going to experience\n",
    "a seminal, fun anecdote,`\n",
    "\n",
    "`517\n",
    "00:18:21,518 --> 00:18:23,394\n",
    "and we are gonna change our stories.`\n",
    "\n",
    "Even after cleaning them with `clean_subs()`, this text is still in two separate objects. We can't recognize that these are supposed to be in a single sentence, but `spaCy` can. We can use the Sentence Boundary Detection functionality to separate these into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2534"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "for sent in doc.sents:\n",
    "    sentences.append(sent.text)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can just say Yale, please.\n",
      "Well, our class's official policy is to not discuss where anyone is attending next year.\n",
      "We don't want them to feel insecure.\n",
      "Very thoughtful.\n",
      "Anyway, I need to go over the end-of-the-year budget numbers we have.\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences[58:63]:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The longer sentences originally spanned two separate subtitles, but were combined into a single sentence. We can more accurately analyze text when they're probably divided into sentences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moviegoer)",
   "language": "python",
   "name": "moviegoer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
